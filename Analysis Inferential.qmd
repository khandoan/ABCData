---
title: "Inferential statistics"
author: "Ana Belem García, Arfa Ghias, Cann Doan, Fatima Tahir"
format: html
editor: visual
---

```{r setup, include=FALSE, echo=TRUE, fig.width=8, fig.height=6, fig.show='hold'}
#install.packages("dplyr")
#install.packages("knitr")
#install.packages("ggplot2")
#install.packages("agricolae")


library(dplyr)
library(knitr)
library(ggplot2)
library(agricolae)

#Folder for results
knitr::opts_chunk$set(fig.path = 'results/')
```

## ANOVA

ANOVAs were used to compare the mean values between treatments and blocks.

```{r}
#| label: ANOVA
# dir("DATA")
data.seeds <- read.csv("DATA/frutasysemillas.csv")

# Remove rows with missing Nseeds
data_clean <- na.omit(data.seeds[, c("Treatment", "Block", "Nseeds")])

# Perform ANOVA
anova_result <- aov(Nseeds ~ Treatment + Block, data = data_clean)
summary(anova_result)



```

Given the past results we can tell the folloing things regarding:

1.  **Treatment**:

    -   The effect of the treatments (CuGA, ZnRep, CapRep) on the response variable (**Nseeds**) is **significant**.

    -   The very small p-value (**2.91e-12**) tells us that **at least one treatment group is different** from the others.

2.  **Block**:

    -   The "Block" factor (replicates) also has a **significant effect** on the number of seeds. This means the blocking variable explains some of the variation in your data.

3.  **Residuals**:

    -   Residuals represent the **unexplained variability** after accounting for treatments and blocks.

#### **Conclusion**:

-   Both the **treatment** and the **block** factors influence the response variable (**Nseeds**).

-   Since the treatment effect is significant, we performed a **post-hoc test** ( Tukey's test) to find out **which treatment groups differ** from each other.

## Tukey test

The **Tukey's post-hoc test** results helps to identify which **pairs of groups** (treatments and blocks) are significantly different after running the ANOVA.

```{r}
tukey_result <- TukeyHSD(anova_result)
tukey_result
```

### **Interpretation of Treatments**:

-   **Significant Differences** (p \< 0.05):

    -   **B-A**: Group B has a significantly lower mean than Group A.

    -   **C-B, D-B, E-B**: Groups C, D, and E have significantly higher means than Group B.

    -   **D-C and E-C**: Groups D and E have significantly higher means than Group C.

-   **Non-Significant Differences**:

    -   **C-A, D-A, E-A, and E-D**: These groups do not show significant differences.

### HSD test

The HSD test is needed to **clearly group** the treatments based on performance and identify which are significantly different.

```{r}
agricolae_result <- HSD.test(anova_result, "Treatment", group = TRUE)
print(agricolae_result$groups)
```

-   **Negative Control (B):**

    -   The mean for B is **0 (lowest group)** and is significantly different from all other treatments.

    -   This confirms that **no intervention (B)** results in **no seed production**, as expected.

```{=html}
<!-- -->
```
-   **Positive Control (A):**

    -   The mean for A is **0.986** and belongs to group **"ab"**, indicating it performs **significantly better than the negative control (B)**.

    -   However, it is **not significantly better than treatments E and D**, meaning these two treatments perform as well as (or slightly better than) the positive control.

## Shapiro Test

The Shapiro-Wilk test is a formal statistical test for normality. The null hypothesis (**H0**) is that the data is **normally distributed**.

```{r}
#| label: Shapiro test
group_counts_nseeds <- data_clean %>%
  group_by(Treatment) %>%
  summarise(unique_count = n_distinct(Nseeds))

# Filter out treatments with only one unique value in 'Nseeds'
data_filtered_nseeds <- data_clean %>%
  filter(Treatment %in% group_counts_nseeds$Treatment[group_counts_nseeds$unique_count > 1])

# Perform the Shapiro-Wilk test on filtered data
shapiro_result_nseeds <- data_filtered_nseeds %>%
  group_by(Treatment) %>%
  summarise(p_value = shapiro.test(Nseeds)$p.value)

# Print the results
print(shapiro_result_nseeds)
# Plot the histogram and QQ plot again
ggplot(data_filtered_nseeds, aes(x = Nseeds)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
  facet_wrap(~ Treatment) +
  theme_minimal() +
  labs(title = "Histogram of Number of Seeds",
       x = "Number of Seeds (Nseeds)",
       y = "Frequency")

ggplot(data_filtered_nseeds, aes(sample = Nseeds)) +
  stat_qq() +
  stat_qq_line() +
  facet_wrap(~ Treatment) +
  theme_minimal() +
  labs(title = "QQ Plot by Treatment")
#This plots show whether this analysis follows Normality.
#The graphs show non-normal distribution

```

A **p-value \< 0.05** means we reject the null hypothesis and conclude the data is **not normally distributed**.

In this case the results let us interpret that:

-   **A**: p = 3.03e-14 → **Reject H₀** (not normal)

-   **C**: p = 1.27e-23 → **Reject H₀** (not normal)

-   **D**: p = 3.88e-15 → **Reject H₀** (not normal)

-   **E**: p = 1.75e-15 → **Reject H₀** (not normal)

Since the normality assumption is violated, we needed to use **non-parametric** alternatives like the **Kruskal-Wallis test** instead of ANOVA. The Kruskal-Wallis test does not assume normality.

## Kruskal-Wallis Test

**Due to lack of normality**, nonparametric methods were selected to compare the means among treatments and blocks by a Kruskal-Wallis rank sum test. 

```{r}
#| label: Kruskal-Wallis
tukey_result <- HSD.test(anova_result, "Treatment", group = TRUE)
tukey_groups <- data.frame(
  Treatment = rownames(tukey_result$groups),
  Group = tukey_result$groups$groups
)

# Calculate means and standard errors for each treatment
summary_data <- data.seeds %>%
  group_by(Treatment) %>%
  summarise(
    mean = mean(Nseeds, na.rm = TRUE),
    se = sd(Nseeds, na.rm = TRUE) / sqrt(n())
  )
  #The standard error measures the precision of the sample mean as an estimate of the population mean.
  #Without dividing by the sqrt the result would simply be the standard deviation, 
  #which measures the spread of individual data points, not the precision of the group mean.


# Merge Tukey groups with summary data
summary_data <- left_join(summary_data, tukey_groups, by = "Treatment")


summary_data$Treatment <- factor(summary_data$Treatment, levels = c("B", "C", "D", "E", "A"))

# Define custom colors for the bars
custom_colors <- c(
  "B" = "#1f77b4",  # Blue
  "C" = "#ff7f0e",  # Orange
  "D" = "#2ca02c",  # Green
  "E" = "#d62728",  # Red
  "A" = "#9467bd"   # Purple
)

# Define custom labels for the x-axis
x_axis_labels <- c(
  "(-) Control (B)",
  "CuGA (C)",
  "ZnRep (D)",
  "CapRep (E)",
  "+ Control (A)"
)
# Create the bar plot with error bars and Tukey groups
ggplot(summary_data, aes(x = Treatment, y = mean, fill = Treatment)) +
  geom_bar(stat = "identity", color = "black", width = 0.7) +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2) +
  geom_text(aes(label = Group, y = mean + se + 0.1), vjust = 0) +
  labs(title = "Mean Number of Seeds by Treatment",
       x = "Treatment",
       y = "Mean Number of Seeds",
       fill = "Treatments") +
  theme_minimal() +
  scale_fill_manual(values = custom_colors) +  # Apply custom bar colors
  scale_x_discrete(labels = x_axis_labels) +  # Use custom x-axis labels
  theme(axis.text.x = element_text(angle = 0, hjust = 0.5),  # Rotate x-axis labels
        legend.position = "right")


```

According to the given graph:

-   **The best option is the negative control (B)**, as it produced the **fewest seeds**.

-   **CuGA (C)** could also be useful, as it significantly reduced seed count, although it’s not as effective as the **negative control**.

-   **ZnRep (D)** and **CapRep (E)** are the least desirable treatments since they resulted in the **highest seed production**.

Thus, you should prioritize treatments that either have **no seeds (B)** or minimize seed count, such as **CuGA (C)**, to achieve fruits with the fewest seeds.
